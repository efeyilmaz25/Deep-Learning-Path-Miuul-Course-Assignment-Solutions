{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment Hyperparameter Optimization**"
      ],
      "metadata": {
        "id": "ivY4NkN0GIdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall tf-keras\n",
        "# !pip install keras-tuner\n",
        "# !pip install tensorflow==2.16.1"
      ],
      "metadata": {
        "id": "E-o3DYkMFtec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0ylQvICFex8",
        "outputId": "08834099-7ab8-4b33-b504-9845b841b419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras Current Version: 3.4.1 Tensorflow Current Version: 2.16.1\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "print(\"Keras Current Version:\", keras.__version__, \"Tensorflow Current Version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imports**"
      ],
      "metadata": {
        "id": "9mMI2d8EGMau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import dump, load\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.initializers import RandomNormal, RandomUniform, GlorotUniform, GlorotNormal, HeNormal\n",
        "from keras.optimizers.schedules import ExponentialDecay\n",
        "from keras_tuner import RandomSearch, GridSearch, BayesianOptimization\n",
        "from keras_tuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "random.seed(46)\n",
        "np.random.seed(46)\n",
        "tf.random.set_seed(46)\n"
      ],
      "metadata": {
        "id": "KoNx_x9pGOZI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Functions**"
      ],
      "metadata": {
        "id": "CyvwNrn0GOdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(filepath):\n",
        "    data = pd.read_csv(filepath)\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(data.drop('Outcome', axis=1))\n",
        "    y = data['Outcome'].values\n",
        "    dump(scaler, 'scaler.joblib')\n",
        "    return X, y\n",
        "\n",
        "def prepare_datasets(X_train, X_val, y_train, y_val, batch_size=None):\n",
        "    if batch_size is None:\n",
        "        batch_size = len(X_train)\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "    train_dataset = train_dataset.shuffle(buffer_size=len(X_train)).batch(batch_size)\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "    val_dataset = val_dataset.batch(batch_size)\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "def plot_training_history(history, train_loss='loss', train_metric='accuracy', val_loss='val_loss', val_metric='val_accuracy'):\n",
        "\n",
        "    #Loss\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(history.history[train_loss], label='Training Loss')\n",
        "    plt.plot(history.history[val_loss], label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Metrics\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(history.history[train_metric], label=f\"Training: {train_metric}\")\n",
        "    plt.plot(history.history[val_metric], label=f\"Validation: {val_metric}\")\n",
        "    plt.title(f'Training and Validation {train_metric} Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(f'train_metric')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def get_best_epoch_details(history):\n",
        "    val_losses = history.history['val_loss']\n",
        "    min_val_loss_index = val_losses.index(min(val_losses))\n",
        "    best_epoch = min_val_loss_index + 1\n",
        "\n",
        "    epoch_details = {}\n",
        "    for key in history.history.keys():\n",
        "        epoch_details[key] = history.history[key][min_val_loss_index]\n",
        "\n",
        "    epoch_details['best_epoch'] = best_epoch\n",
        "    print(f\"Best epoch details: {epoch_details}\")"
      ],
      "metadata": {
        "id": "pHbwDmFFGSpk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preparation**"
      ],
      "metadata": {
        "id": "5UCiiKGzG4l0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = preprocess_data('diabetes.csv')\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=5)\n",
        "\n",
        "train_ds, val_ds = prepare_datasets(X_train, X_val, y_train, y_val, batch_size=32)"
      ],
      "metadata": {
        "id": "T67arKVEIS7_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 1: Create the Hyperparameter Search Space According to the Following Values:**"
      ],
      "metadata": {
        "id": "EU_rX5aUnH_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Layer count**: 1-10\n",
        "\n",
        "**Unit count**: Between 32-512, increasing by 16.\n",
        "\n",
        "**Activation functions**: relu, tanh, sigmoid\n",
        "\n",
        "**l2**: 0.0001-0.01\n",
        "\n",
        "**dropout**: Between 0.1-0.5, increasing by 0.05.\n",
        "\n",
        "**initial learning rate**: 0.0001-0.01 (1e-4 - 1e-2)\n",
        "\n",
        "**learning rate scheduler**: decay steps: 20\n",
        "\n",
        "**optimizers**: 'sgd', 'adam', 'rmsprop' (can remain as is)\n",
        "\n",
        "**Random search:** epoch count must be at least 200\n",
        "\n",
        "You can make other settings as you wish."
      ],
      "metadata": {
        "id": "q6kIylH5nMSE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 1 Solution**"
      ],
      "metadata": {
        "id": "LKjjNKVpnVr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(train_ds.element_spec[0].shape[1],)))\n",
        "\n",
        "    # Hidden layers, activation functions, l2, Dropout\n",
        "    for i in range(hp.Int('num_layers', 1, 10)):\n",
        "\n",
        "        model.add(Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=16),\n",
        "                        activation=hp.Choice('activation_' + str(i), values=['relu', 'tanh', 'sigmoid']),\n",
        "                        kernel_regularizer=l2(hp.Float('l2_' + str(i), min_value=0.0001, max_value=0.01, sampling='log'))))\n",
        "\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(hp.Float('dropout_' + str(i), min_value=0.1, max_value=0.5, step=0.05)))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Learning rate schedule\n",
        "    initial_learning_rate = hp.Float('initial_learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
        "\n",
        "    lr_schedule = ExponentialDecay(\n",
        "        initial_learning_rate=initial_learning_rate,\n",
        "        decay_steps=20,\n",
        "        decay_rate=0.96,\n",
        "        staircase=True\n",
        "    )\n",
        "\n",
        "    # optimizers\n",
        "    optimizer_choice = hp.Choice('optimizer', values=['sgd', 'adam', \"rmsprop\"])\n",
        "    if optimizer_choice == 'sgd':\n",
        "        optimizer = SGD(\n",
        "            learning_rate=lr_schedule,\n",
        "            momentum=hp.Float('momentum', min_value=0.0, max_value=0.9, step=0.1)\n",
        "        )\n",
        "    elif optimizer_choice == 'adam':\n",
        "        optimizer = Adam(\n",
        "            learning_rate=lr_schedule,\n",
        "            beta_1=hp.Float('beta1', min_value=0.85, max_value=0.99, step=0.01),\n",
        "            beta_2=hp.Float('beta2', min_value=0.999, max_value=0.9999, step=0.0001),\n",
        "            epsilon=hp.Float('epsilon', min_value=1e-8, max_value=1e-7, step=1e-8)\n",
        "        )\n",
        "\n",
        "    elif optimizer_choice == 'rmsprop':\n",
        "        optimizer = RMSprop(\n",
        "            learning_rate=lr_schedule,\n",
        "            rho=hp.Float('rho', min_value=0.8, max_value=0.99, step=0.01),\n",
        "            epsilon=hp.Float('epsilon', min_value=1e-10, max_value=1e-8, step=1e-10),\n",
        "            momentum=hp.Float('momentum', min_value=0.0, max_value=0.9, step=0.1)\n",
        "        )\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "XUJWPx6wnXK5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 2: Start the Search With the Epoch Count Being 200. Other settings Can Remain the Same.**"
      ],
      "metadata": {
        "id": "g9iBEvDOrkMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 2 Solution**"
      ],
      "metadata": {
        "id": "wTWHMs2prsZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_search_tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=20,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True)\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=20,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True)\n"
      ],
      "metadata": {
        "id": "_LUQvPo5s2TG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_search_tuner.search(train_ds,\n",
        "                           epochs=200,\n",
        "                           validation_data=val_ds,\n",
        "                           callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESpYqnMos2M8",
        "outputId": "497df891-4c17-4541-c84b-ec8238be0aef"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 01m 14s]\n",
            "val_loss: 3.0624544620513916\n",
            "\n",
            "Best val_loss So Far: 0.5032702088356018\n",
            "Total elapsed time: 00h 19m 46s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_search_tuner.search_space_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkUhPHUpuFGv",
        "outputId": "dba4b153-c947-40d2-8959-966722344588"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 48\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 10, 'step': 1, 'sampling': 'linear'}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 16, 'sampling': 'linear'}\n",
            "activation_0 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
            "l2_0 (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
            "dropout_0 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
            "initial_learning_rate (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
            "optimizer (Choice)\n",
            "{'default': 'sgd', 'conditions': [], 'values': ['sgd', 'adam', 'rmsprop'], 'ordered': False}\n",
            "momentum (Float)\n",
            "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.9, 'step': 0.1, 'sampling': 'linear'}\n",
            "units_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 16, 'sampling': 'linear'}\n",
            "activation_1 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
            "l2_1 (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
            "dropout_1 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
            "units_2 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 16, 'sampling': 'linear'}\n",
            "activation_2 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
            "l2_2 (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
            "dropout_2 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
            "units_3 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 16, 'sampling': 'linear'}\n",
            "activation_3 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
            "l2_3 (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
            "dropout_3 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
            "units_4 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 16, 'sampling': 'linear'}\n",
            "activation_4 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
            "l2_4 (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
            "dropout_4 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
            "beta1 (Float)\n",
            "{'default': 0.85, 'conditions': [], 'min_value': 0.85, 'max_value': 0.99, 'step': 0.01, 'sampling': 'linear'}\n",
            "beta2 (Float)\n",
            "{'default': 0.999, 'conditions': [], 'min_value': 0.999, 'max_value': 0.9999, 'step': 0.0001, 'sampling': 'linear'}\n",
            "epsilon (Float)\n",
            "{'default': 1e-08, 'conditions': [], 'min_value': 1e-08, 'max_value': 1e-07, 'step': 1e-08, 'sampling': 'linear'}\n",
            "units_5 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 16, 'sampling': 'linear'}\n",
            "activation_5 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
            "l2_5 (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
            "dropout_5 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
            "units_6 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 16, 'sampling': 'linear'}\n",
            "activation_6 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
            "l2_6 (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
            "dropout_6 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
            "units_7 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 16, 'sampling': 'linear'}\n",
            "activation_7 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
            "l2_7 (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
            "dropout_7 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
            "units_8 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 16, 'sampling': 'linear'}\n",
            "activation_8 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
            "l2_8 (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
            "dropout_8 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
            "units_9 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 16, 'sampling': 'linear'}\n",
            "activation_9 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
            "l2_9 (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
            "dropout_9 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
            "rho (Float)\n",
            "{'default': 0.8, 'conditions': [], 'min_value': 0.8, 'max_value': 0.99, 'step': 0.01, 'sampling': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_search_tuner.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5e27_bguHDN",
        "outputId": "b58647e8-739e-4092-de35-cfc405a29c60"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_loss\", direction=\"min\")\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "units_0: 496\n",
            "activation_0: relu\n",
            "l2_0: 0.0008678811964271953\n",
            "dropout_0: 0.35\n",
            "initial_learning_rate: 0.0007443190353728441\n",
            "optimizer: sgd\n",
            "momentum: 0.0\n",
            "units_1: 192\n",
            "activation_1: relu\n",
            "l2_1: 0.0008083461993086267\n",
            "dropout_1: 0.30000000000000004\n",
            "units_2: 432\n",
            "activation_2: relu\n",
            "l2_2: 0.0008639199562623075\n",
            "dropout_2: 0.15000000000000002\n",
            "units_3: 320\n",
            "activation_3: tanh\n",
            "l2_3: 0.0016212150201753844\n",
            "dropout_3: 0.30000000000000004\n",
            "units_4: 48\n",
            "activation_4: relu\n",
            "l2_4: 0.0002522332696647429\n",
            "dropout_4: 0.4\n",
            "beta1: 0.89\n",
            "beta2: 0.9994999999999999\n",
            "epsilon: 6e-08\n",
            "Score: 0.5032702088356018\n",
            "\n",
            "Trial 06 summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "units_0: 272\n",
            "activation_0: relu\n",
            "l2_0: 0.007321002854350309\n",
            "dropout_0: 0.4\n",
            "initial_learning_rate: 0.0025284101838969467\n",
            "optimizer: adam\n",
            "momentum: 0.4\n",
            "units_1: 288\n",
            "activation_1: sigmoid\n",
            "l2_1: 0.0018539278556818578\n",
            "dropout_1: 0.15000000000000002\n",
            "units_2: 176\n",
            "activation_2: sigmoid\n",
            "l2_2: 0.0007499821321573125\n",
            "dropout_2: 0.4\n",
            "units_3: 80\n",
            "activation_3: tanh\n",
            "l2_3: 0.001309772338927608\n",
            "dropout_3: 0.25\n",
            "units_4: 224\n",
            "activation_4: sigmoid\n",
            "l2_4: 0.003319293040537141\n",
            "dropout_4: 0.1\n",
            "beta1: 0.96\n",
            "beta2: 0.999\n",
            "epsilon: 1e-08\n",
            "units_5: 224\n",
            "activation_5: sigmoid\n",
            "l2_5: 0.002096527920915054\n",
            "dropout_5: 0.35\n",
            "units_6: 432\n",
            "activation_6: sigmoid\n",
            "l2_6: 0.0007836322753488304\n",
            "dropout_6: 0.45000000000000007\n",
            "units_7: 416\n",
            "activation_7: tanh\n",
            "l2_7: 0.004840503032482819\n",
            "dropout_7: 0.5\n",
            "units_8: 112\n",
            "activation_8: relu\n",
            "l2_8: 0.00028263424638544555\n",
            "dropout_8: 0.15000000000000002\n",
            "units_9: 80\n",
            "activation_9: tanh\n",
            "l2_9: 0.009021311428169284\n",
            "dropout_9: 0.15000000000000002\n",
            "Score: 0.5036947131156921\n",
            "\n",
            "Trial 00 summary\n",
            "Hyperparameters:\n",
            "num_layers: 5\n",
            "units_0: 384\n",
            "activation_0: sigmoid\n",
            "l2_0: 0.0021726762931534105\n",
            "dropout_0: 0.2\n",
            "initial_learning_rate: 0.0008380093243360302\n",
            "optimizer: adam\n",
            "momentum: 0.2\n",
            "units_1: 32\n",
            "activation_1: relu\n",
            "l2_1: 0.0001\n",
            "dropout_1: 0.1\n",
            "units_2: 32\n",
            "activation_2: relu\n",
            "l2_2: 0.0001\n",
            "dropout_2: 0.1\n",
            "units_3: 32\n",
            "activation_3: relu\n",
            "l2_3: 0.0001\n",
            "dropout_3: 0.1\n",
            "units_4: 32\n",
            "activation_4: relu\n",
            "l2_4: 0.0001\n",
            "dropout_4: 0.1\n",
            "beta1: 0.85\n",
            "beta2: 0.999\n",
            "epsilon: 1e-08\n",
            "Score: 0.5059388279914856\n",
            "\n",
            "Trial 08 summary\n",
            "Hyperparameters:\n",
            "num_layers: 5\n",
            "units_0: 416\n",
            "activation_0: sigmoid\n",
            "l2_0: 0.0007000914691723327\n",
            "dropout_0: 0.5\n",
            "initial_learning_rate: 0.0017450034397126506\n",
            "optimizer: rmsprop\n",
            "momentum: 0.5\n",
            "units_1: 464\n",
            "activation_1: tanh\n",
            "l2_1: 0.00018733758254691512\n",
            "dropout_1: 0.30000000000000004\n",
            "units_2: 448\n",
            "activation_2: relu\n",
            "l2_2: 0.0015040477086424111\n",
            "dropout_2: 0.30000000000000004\n",
            "units_3: 240\n",
            "activation_3: tanh\n",
            "l2_3: 0.0005437534080408972\n",
            "dropout_3: 0.35\n",
            "units_4: 368\n",
            "activation_4: tanh\n",
            "l2_4: 0.0025775021806983384\n",
            "dropout_4: 0.45000000000000007\n",
            "beta1: 0.88\n",
            "beta2: 0.9993\n",
            "epsilon: 5e-08\n",
            "units_5: 224\n",
            "activation_5: tanh\n",
            "l2_5: 0.0003357459276085053\n",
            "dropout_5: 0.1\n",
            "units_6: 272\n",
            "activation_6: tanh\n",
            "l2_6: 0.00030048159810771484\n",
            "dropout_6: 0.5\n",
            "units_7: 32\n",
            "activation_7: sigmoid\n",
            "l2_7: 0.0020853562398959924\n",
            "dropout_7: 0.35\n",
            "units_8: 32\n",
            "activation_8: sigmoid\n",
            "l2_8: 0.001846808222764879\n",
            "dropout_8: 0.4\n",
            "units_9: 336\n",
            "activation_9: relu\n",
            "l2_9: 0.0008979340534482525\n",
            "dropout_9: 0.45000000000000007\n",
            "rho: 0.8\n",
            "Score: 0.5557807087898254\n",
            "\n",
            "Trial 17 summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "units_0: 256\n",
            "activation_0: tanh\n",
            "l2_0: 0.00035984239364919557\n",
            "dropout_0: 0.2\n",
            "initial_learning_rate: 0.0004917677957250333\n",
            "optimizer: rmsprop\n",
            "momentum: 0.7000000000000001\n",
            "units_1: 496\n",
            "activation_1: tanh\n",
            "l2_1: 0.000596921247059964\n",
            "dropout_1: 0.2\n",
            "units_2: 32\n",
            "activation_2: tanh\n",
            "l2_2: 0.0008657947905507466\n",
            "dropout_2: 0.35\n",
            "units_3: 480\n",
            "activation_3: sigmoid\n",
            "l2_3: 0.002683948539131404\n",
            "dropout_3: 0.25\n",
            "units_4: 512\n",
            "activation_4: tanh\n",
            "l2_4: 0.002206626353477078\n",
            "dropout_4: 0.1\n",
            "beta1: 0.96\n",
            "beta2: 0.999\n",
            "epsilon: 9e-08\n",
            "units_5: 64\n",
            "activation_5: sigmoid\n",
            "l2_5: 0.000164990621482157\n",
            "dropout_5: 0.30000000000000004\n",
            "units_6: 144\n",
            "activation_6: tanh\n",
            "l2_6: 0.006157704430170601\n",
            "dropout_6: 0.1\n",
            "units_7: 32\n",
            "activation_7: sigmoid\n",
            "l2_7: 0.000924971251795598\n",
            "dropout_7: 0.4\n",
            "units_8: 480\n",
            "activation_8: tanh\n",
            "l2_8: 0.0006270538867968894\n",
            "dropout_8: 0.15000000000000002\n",
            "units_9: 32\n",
            "activation_9: tanh\n",
            "l2_9: 0.004824169955239995\n",
            "dropout_9: 0.35\n",
            "rho: 0.8300000000000001\n",
            "Score: 0.5660029053688049\n",
            "\n",
            "Trial 10 summary\n",
            "Hyperparameters:\n",
            "num_layers: 5\n",
            "units_0: 384\n",
            "activation_0: tanh\n",
            "l2_0: 0.00016899315089921891\n",
            "dropout_0: 0.35\n",
            "initial_learning_rate: 0.0047556340933281645\n",
            "optimizer: adam\n",
            "momentum: 0.2\n",
            "units_1: 128\n",
            "activation_1: tanh\n",
            "l2_1: 0.0008019020731570195\n",
            "dropout_1: 0.25\n",
            "units_2: 320\n",
            "activation_2: relu\n",
            "l2_2: 0.00017451606591827412\n",
            "dropout_2: 0.30000000000000004\n",
            "units_3: 336\n",
            "activation_3: tanh\n",
            "l2_3: 0.0013257717103432026\n",
            "dropout_3: 0.4\n",
            "units_4: 512\n",
            "activation_4: relu\n",
            "l2_4: 0.008367477423054924\n",
            "dropout_4: 0.4\n",
            "beta1: 0.89\n",
            "beta2: 0.9993\n",
            "epsilon: 6e-08\n",
            "units_5: 352\n",
            "activation_5: sigmoid\n",
            "l2_5: 0.0029224928707254597\n",
            "dropout_5: 0.2\n",
            "units_6: 400\n",
            "activation_6: tanh\n",
            "l2_6: 0.001668763294937981\n",
            "dropout_6: 0.2\n",
            "units_7: 512\n",
            "activation_7: tanh\n",
            "l2_7: 0.0018413022573426278\n",
            "dropout_7: 0.4\n",
            "units_8: 416\n",
            "activation_8: relu\n",
            "l2_8: 0.00022491452958964034\n",
            "dropout_8: 0.30000000000000004\n",
            "units_9: 464\n",
            "activation_9: relu\n",
            "l2_9: 0.0007251386418532748\n",
            "dropout_9: 0.1\n",
            "rho: 0.93\n",
            "Score: 0.6099029779434204\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "units_0: 368\n",
            "activation_0: relu\n",
            "l2_0: 0.002806695072547798\n",
            "dropout_0: 0.4\n",
            "initial_learning_rate: 0.002112765859059582\n",
            "optimizer: adam\n",
            "momentum: 0.30000000000000004\n",
            "units_1: 240\n",
            "activation_1: tanh\n",
            "l2_1: 0.0007952701184972202\n",
            "dropout_1: 0.35\n",
            "units_2: 96\n",
            "activation_2: relu\n",
            "l2_2: 0.001192978696747447\n",
            "dropout_2: 0.15000000000000002\n",
            "units_3: 352\n",
            "activation_3: tanh\n",
            "l2_3: 0.00028516653530849865\n",
            "dropout_3: 0.35\n",
            "units_4: 112\n",
            "activation_4: sigmoid\n",
            "l2_4: 0.001490547737726647\n",
            "dropout_4: 0.30000000000000004\n",
            "beta1: 0.94\n",
            "beta2: 0.9996\n",
            "epsilon: 2e-08\n",
            "Score: 0.7463736534118652\n",
            "\n",
            "Trial 15 summary\n",
            "Hyperparameters:\n",
            "num_layers: 5\n",
            "units_0: 128\n",
            "activation_0: sigmoid\n",
            "l2_0: 0.0004310172695292681\n",
            "dropout_0: 0.4\n",
            "initial_learning_rate: 0.00013801081453585753\n",
            "optimizer: rmsprop\n",
            "momentum: 0.0\n",
            "units_1: 112\n",
            "activation_1: tanh\n",
            "l2_1: 0.0001097893053558189\n",
            "dropout_1: 0.4\n",
            "units_2: 352\n",
            "activation_2: relu\n",
            "l2_2: 0.00019629629306016258\n",
            "dropout_2: 0.25\n",
            "units_3: 240\n",
            "activation_3: tanh\n",
            "l2_3: 0.0007321845733528145\n",
            "dropout_3: 0.45000000000000007\n",
            "units_4: 144\n",
            "activation_4: relu\n",
            "l2_4: 0.0002607860606751251\n",
            "dropout_4: 0.15000000000000002\n",
            "beta1: 0.98\n",
            "beta2: 0.9992\n",
            "epsilon: 5e-08\n",
            "units_5: 144\n",
            "activation_5: tanh\n",
            "l2_5: 0.005018201348461449\n",
            "dropout_5: 0.15000000000000002\n",
            "units_6: 80\n",
            "activation_6: sigmoid\n",
            "l2_6: 0.00020366217049846844\n",
            "dropout_6: 0.2\n",
            "units_7: 112\n",
            "activation_7: tanh\n",
            "l2_7: 0.00020648736880041844\n",
            "dropout_7: 0.1\n",
            "units_8: 128\n",
            "activation_8: tanh\n",
            "l2_8: 0.0004918694064742597\n",
            "dropout_8: 0.5\n",
            "units_9: 464\n",
            "activation_9: relu\n",
            "l2_9: 0.00023668462510856045\n",
            "dropout_9: 0.35\n",
            "rho: 0.91\n",
            "Score: 0.7547050714492798\n",
            "\n",
            "Trial 03 summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "units_0: 96\n",
            "activation_0: tanh\n",
            "l2_0: 0.00023368356870813616\n",
            "dropout_0: 0.35\n",
            "initial_learning_rate: 0.00010552073747278635\n",
            "optimizer: sgd\n",
            "momentum: 0.1\n",
            "units_1: 176\n",
            "activation_1: tanh\n",
            "l2_1: 0.001468267917477422\n",
            "dropout_1: 0.2\n",
            "units_2: 80\n",
            "activation_2: tanh\n",
            "l2_2: 0.0009621896931286941\n",
            "dropout_2: 0.1\n",
            "units_3: 416\n",
            "activation_3: sigmoid\n",
            "l2_3: 0.0069108517839247645\n",
            "dropout_3: 0.1\n",
            "units_4: 480\n",
            "activation_4: sigmoid\n",
            "l2_4: 0.0009867496902904826\n",
            "dropout_4: 0.15000000000000002\n",
            "beta1: 0.9099999999999999\n",
            "beta2: 0.9991\n",
            "epsilon: 1e-08\n",
            "Score: 0.8174105286598206\n",
            "\n",
            "Trial 12 summary\n",
            "Hyperparameters:\n",
            "num_layers: 9\n",
            "units_0: 240\n",
            "activation_0: sigmoid\n",
            "l2_0: 0.0026021566587086636\n",
            "dropout_0: 0.4\n",
            "initial_learning_rate: 0.0008147218760142675\n",
            "optimizer: rmsprop\n",
            "momentum: 0.5\n",
            "units_1: 512\n",
            "activation_1: relu\n",
            "l2_1: 0.0007017901807490971\n",
            "dropout_1: 0.35\n",
            "units_2: 160\n",
            "activation_2: relu\n",
            "l2_2: 0.00013529562061620576\n",
            "dropout_2: 0.1\n",
            "units_3: 448\n",
            "activation_3: relu\n",
            "l2_3: 0.0015313710767521785\n",
            "dropout_3: 0.35\n",
            "units_4: 416\n",
            "activation_4: relu\n",
            "l2_4: 0.0015636893680288113\n",
            "dropout_4: 0.15000000000000002\n",
            "beta1: 0.85\n",
            "beta2: 0.9997\n",
            "epsilon: 7e-08\n",
            "units_5: 128\n",
            "activation_5: sigmoid\n",
            "l2_5: 0.00024026393786951466\n",
            "dropout_5: 0.25\n",
            "units_6: 160\n",
            "activation_6: tanh\n",
            "l2_6: 0.004023995389189576\n",
            "dropout_6: 0.35\n",
            "units_7: 192\n",
            "activation_7: relu\n",
            "l2_7: 0.005143948504561813\n",
            "dropout_7: 0.35\n",
            "units_8: 448\n",
            "activation_8: sigmoid\n",
            "l2_8: 0.0013808737637721871\n",
            "dropout_8: 0.25\n",
            "units_9: 128\n",
            "activation_9: tanh\n",
            "l2_9: 0.0013556239419633572\n",
            "dropout_9: 0.2\n",
            "rho: 0.88\n",
            "Score: 1.0514345169067383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 3: Bring the Best 3 Hyperparameter Sets, Save Them Separately, Examine Their Values, and Comment on Some Hyperparameter Values.**"
      ],
      "metadata": {
        "id": "WMYmqJ7NrxDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 3 Solution**"
      ],
      "metadata": {
        "id": "HO0WDQwlr7eH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = random_search_tuner.get_best_hyperparameters(num_trials=3)"
      ],
      "metadata": {
        "id": "rUHwwQahuK9_"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps_1 = best_hps[0]\n",
        "best_hps_2 = best_hps[1]\n",
        "best_hps_3 = best_hps[2]"
      ],
      "metadata": {
        "id": "PplVZVffy0es"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"First Best Hyperparameters: {best_hps_1.values}\")\n",
        "print(f\"Second Best Hyperparameters: {best_hps_2.values}\")\n",
        "print(f\"Third Best Hyperparameters: {best_hps_3.values}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nZWRssDuQcA",
        "outputId": "40e5e628-bbcf-40d0-8a9f-01a72ec0771a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Best Hyperparameters: {'num_layers': 1, 'units_0': 496, 'activation_0': 'relu', 'l2_0': 0.0008678811964271953, 'dropout_0': 0.35, 'initial_learning_rate': 0.0007443190353728441, 'optimizer': 'sgd', 'momentum': 0.0, 'units_1': 192, 'activation_1': 'relu', 'l2_1': 0.0008083461993086267, 'dropout_1': 0.30000000000000004, 'units_2': 432, 'activation_2': 'relu', 'l2_2': 0.0008639199562623075, 'dropout_2': 0.15000000000000002, 'units_3': 320, 'activation_3': 'tanh', 'l2_3': 0.0016212150201753844, 'dropout_3': 0.30000000000000004, 'units_4': 48, 'activation_4': 'relu', 'l2_4': 0.0002522332696647429, 'dropout_4': 0.4, 'beta1': 0.89, 'beta2': 0.9994999999999999, 'epsilon': 6e-08}\n",
            "Second Best Hyperparameters: {'num_layers': 1, 'units_0': 272, 'activation_0': 'relu', 'l2_0': 0.007321002854350309, 'dropout_0': 0.4, 'initial_learning_rate': 0.0025284101838969467, 'optimizer': 'adam', 'momentum': 0.4, 'units_1': 288, 'activation_1': 'sigmoid', 'l2_1': 0.0018539278556818578, 'dropout_1': 0.15000000000000002, 'units_2': 176, 'activation_2': 'sigmoid', 'l2_2': 0.0007499821321573125, 'dropout_2': 0.4, 'units_3': 80, 'activation_3': 'tanh', 'l2_3': 0.001309772338927608, 'dropout_3': 0.25, 'units_4': 224, 'activation_4': 'sigmoid', 'l2_4': 0.003319293040537141, 'dropout_4': 0.1, 'beta1': 0.96, 'beta2': 0.999, 'epsilon': 1e-08, 'units_5': 224, 'activation_5': 'sigmoid', 'l2_5': 0.002096527920915054, 'dropout_5': 0.35, 'units_6': 432, 'activation_6': 'sigmoid', 'l2_6': 0.0007836322753488304, 'dropout_6': 0.45000000000000007, 'units_7': 416, 'activation_7': 'tanh', 'l2_7': 0.004840503032482819, 'dropout_7': 0.5, 'units_8': 112, 'activation_8': 'relu', 'l2_8': 0.00028263424638544555, 'dropout_8': 0.15000000000000002, 'units_9': 80, 'activation_9': 'tanh', 'l2_9': 0.009021311428169284, 'dropout_9': 0.15000000000000002}\n",
            "Third Best Hyperparameters: {'num_layers': 5, 'units_0': 384, 'activation_0': 'sigmoid', 'l2_0': 0.0021726762931534105, 'dropout_0': 0.2, 'initial_learning_rate': 0.0008380093243360302, 'optimizer': 'adam', 'momentum': 0.2, 'units_1': 32, 'activation_1': 'relu', 'l2_1': 0.0001, 'dropout_1': 0.1, 'units_2': 32, 'activation_2': 'relu', 'l2_2': 0.0001, 'dropout_2': 0.1, 'units_3': 32, 'activation_3': 'relu', 'l2_3': 0.0001, 'dropout_3': 0.1, 'units_4': 32, 'activation_4': 'relu', 'l2_4': 0.0001, 'dropout_4': 0.1, 'beta1': 0.85, 'beta2': 0.999, 'epsilon': 1e-08}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen in the results of our searches, the layer numbers came as 1, 1 and 5 respectively. The layer number of our first two best models was determined as 1. **However, another common feature was determined as relu as the activation function.** In our third model, unlike these, the sigmoid function was determined.\n",
        "\n",
        "**Although we sense a degree of illogicality in determining sigmoid as the activation function in our third model, we do not make a definitive comment. The reason for this is that the sigmoid function compresses the outputs between 0, 0 and 1, 1. This can cause information loss by narrowing the output range too much, especially in a layer that receives a large amount of information, such as the first layer. This means that the model cannot sufficiently enrich the information transferred to the deep layers. The sigmoid function increases the problem of shrinking gradients, especially in large deep networks. If the model has a large enough data set and a very deep structure is used, the gradients can shrink, causing updates to be ineffective.**\n",
        "\n",
        "If we continue to examine the parameter combinations, the use of the sigmoid function as the activation function in the intermediate layers of the second best combination creates doubt."
      ],
      "metadata": {
        "id": "CnIHVoUy2nek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 4: Select the Best 3 Models.**"
      ],
      "metadata": {
        "id": "WpHUXn0Tr96j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 4 Solution**"
      ],
      "metadata": {
        "id": "pakkJkTAsC6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = random_search_tuner.get_best_models(num_models=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPIyDevWzK9-",
        "outputId": "85cb9406-e052-48f4-adc1-7e6d6bcd80d5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 1 variables whereas the saved optimizer has 13 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 1 variables whereas the saved optimizer has 45 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_models_1 = best_models[0]\n",
        "best_models_2 = best_models[1]\n",
        "best_models_3 = best_models[2]"
      ],
      "metadata": {
        "id": "HVszHpVTztAp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "gf2wD3kazs7M",
        "outputId": "284e0b67-72c4-4cc8-e5ea-96cce58a0732"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m496\u001b[0m)                 │           \u001b[38;5;34m4,464\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m496\u001b[0m)                 │           \u001b[38;5;34m1,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m496\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m497\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">496</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,464</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">496</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">496</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">497</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,945\u001b[0m (27.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,945</span> (27.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,953\u001b[0m (23.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,953</span> (23.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m992\u001b[0m (3.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">992</span> (3.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_models_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "yCGOd-w7zs1H",
        "outputId": "a5c196b4-b5d5-46a8-e31b-76e6f092b6b7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m272\u001b[0m)                 │           \u001b[38;5;34m2,448\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m272\u001b[0m)                 │           \u001b[38;5;34m1,088\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m272\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m273\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,448</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">273</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,809\u001b[0m (14.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,809</span> (14.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,265\u001b[0m (12.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,265</span> (12.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m544\u001b[0m (2.12 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> (2.12 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_models_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "ICtXq_EDz4Lr",
        "outputId": "3334fa89-6571-490f-fffd-27ae5502f244"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)                 │           \u001b[38;5;34m3,456\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)                 │           \u001b[38;5;34m1,536\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m1,056\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m1,056\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m1,056\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,025\u001b[0m (82.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,025</span> (82.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,001\u001b[0m (78.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,001</span> (78.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 5: Calculate the Model Success of the Top 3 Models Through a Loop**"
      ],
      "metadata": {
        "id": "Rjw1RrlXsFEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 5 Solution**"
      ],
      "metadata": {
        "id": "u7jJPUrhsMLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, model in enumerate(best_models):\n",
        "    loss, acc = model.evaluate(val_ds, verbose=0)\n",
        "    print(f\"Best Model {i+1}, Validation loss: {loss}, Validation Accuracy: {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQM4mbhPzqvI",
        "outputId": "548c9d4c-a6eb-42f2-f9c2-e451ee3f37f1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model 1, Validation loss: 0.5032702088356018, Validation Accuracy: 0.7727272510528564\n",
            "Best Model 2, Validation loss: 0.5036947131156921, Validation Accuracy: 0.7662337422370911\n",
            "Best Model 3, Validation loss: 0.5059388279914856, Validation Accuracy: 0.7727272510528564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 6: Why is There a Difference Between the Accuracy Values ​​of the Models? We Expect the Top Model to be the Best, If Not, Why Doesn't Whe Top One Have the Highest Accuracy Value?**"
      ],
      "metadata": {
        "id": "no06VF12sNnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 6 Solution**"
      ],
      "metadata": {
        "id": "a4R-VKmJsy9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the highest accuracy value belongs to the top model. However, we determined the combinations by monitoring the **'val_loss'** metric. Therefore, even if the accuracy value of the top model was lower than the other two models, it would still be the best model."
      ],
      "metadata": {
        "id": "sSqIfcEb5LIZ"
      }
    }
  ]
}